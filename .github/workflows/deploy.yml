# GitHub Actions workflow for deploying Cabruca Segmentation to AWS Brazil
name: Deploy to AWS Brazil

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'docker/**'
      - 'terraform/**'
      - '.github/workflows/deploy.yml'
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'staging'
        type: choice
        options:
          - dev
          - staging
          - prod

env:
  AWS_REGION: sa-east-1
  ECR_REPOSITORY: cabruca-segmentation
  ECS_CLUSTER: cabruca-segmentation-cluster
  
jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
      
      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8
      
      - name: Run linting
        run: |
          flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
      
      - name: Run tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella

  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    strategy:
      matrix:
        service: [api, streamlit, inference]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ matrix.service }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-${{ matrix.service }}-
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile.${{ matrix.service }}
          push: true
          tags: |
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ matrix.service }}-latest
            ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ matrix.service }}-${{ github.sha }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
          build-args: |
            SERVICE=${{ matrix.service }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
      
      - name: Move cache
        run: |
          rm -rf /tmp/.buildx-cache
          mv /tmp/.buildx-cache-new /tmp/.buildx-cache

  deploy:
    name: Deploy to ECS
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    environment:
      name: ${{ github.event.inputs.environment || 'staging' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      
      - name: Update ECS task definitions
        run: |
          ENVIRONMENT=${{ github.event.inputs.environment || 'staging' }}
          
          for SERVICE in api streamlit inference; do
            # Download current task definition
            aws ecs describe-task-definition \
              --task-definition cabruca-segmentation-${SERVICE} \
              --query taskDefinition > task-definition-${SERVICE}.json
            
            # Update the image
            sed -i "s|${ECR_REPOSITORY}:${SERVICE}-.*|${ECR_REPOSITORY}:${SERVICE}-${GITHUB_SHA}|g" \
              task-definition-${SERVICE}.json
            
            # Register new task definition
            aws ecs register-task-definition \
              --cli-input-json file://task-definition-${SERVICE}.json
            
            # Update service
            aws ecs update-service \
              --cluster ${ECS_CLUSTER}-${ENVIRONMENT} \
              --service cabruca-segmentation-${SERVICE} \
              --task-definition cabruca-segmentation-${SERVICE} \
              --force-new-deployment
          done
      
      - name: Wait for deployment
        run: |
          ENVIRONMENT=${{ github.event.inputs.environment || 'staging' }}
          
          for SERVICE in api streamlit; do
            aws ecs wait services-stable \
              --cluster ${ECS_CLUSTER}-${ENVIRONMENT} \
              --services cabruca-segmentation-${SERVICE}
          done
      
      - name: Run smoke tests
        run: |
          ENVIRONMENT=${{ github.event.inputs.environment || 'staging' }}
          
          # Get the load balancer URL
          LB_URL=$(aws elbv2 describe-load-balancers \
            --names cabruca-segmentation-${ENVIRONMENT}-alb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)
          
          # Test API health endpoint
          curl -f https://${LB_URL}/health || exit 1
          
          # Test Streamlit dashboard
          curl -f https://${LB_URL}/dashboard || exit 1
      
      - name: Notify deployment
        if: success()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Deployment to ${{ github.event.inputs.environment || "staging" }} successful!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  terraform:
    name: Apply Terraform
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.environment == 'prod'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init
      
      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          terraform plan \
            -var="environment=prod" \
            -var="aws_region=${AWS_REGION}" \
            -out=tfplan
      
      - name: Terraform Apply
        working-directory: ./terraform
        if: github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve tfplan
      
      - name: Output Terraform values
        working-directory: ./terraform
        run: |
          echo "Load Balancer URL: $(terraform output -raw load_balancer_url)"
          echo "CloudFront URL: $(terraform output -raw cloudfront_url)"
          echo "API Endpoint: $(terraform output -raw api_endpoint)"

  rollback:
    name: Rollback Deployment
    runs-on: ubuntu-latest
    needs: deploy
    if: failure()
    
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Rollback ECS services
        run: |
          ENVIRONMENT=${{ github.event.inputs.environment || 'staging' }}
          
          for SERVICE in api streamlit inference; do
            # Get the previous task definition
            PREVIOUS_TASK_DEF=$(aws ecs describe-services \
              --cluster ${ECS_CLUSTER}-${ENVIRONMENT} \
              --services cabruca-segmentation-${SERVICE} \
              --query 'services[0].deployments[1].taskDefinition' \
              --output text)
            
            if [ ! -z "$PREVIOUS_TASK_DEF" ]; then
              # Update service with previous task definition
              aws ecs update-service \
                --cluster ${ECS_CLUSTER}-${ENVIRONMENT} \
                --service cabruca-segmentation-${SERVICE} \
                --task-definition ${PREVIOUS_TASK_DEF} \
                --force-new-deployment
            fi
          done
      
      - name: Notify rollback
        uses: 8398a7/action-slack@v3
        with:
          status: 'failure'
          text: 'Deployment failed! Rolling back to previous version.'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}